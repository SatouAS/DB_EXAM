{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Добрый день, так как в задании просят лишь один файл в формате ipynb, то смогу в этом файле описать только шаг 3 (т.к. на питоне только он). Работа проводилась мной pyCharm многими файлами, все бд настраивались в качестве контейнеров в докер. Если будут вопросы по другим шагам или структуре, все это я выложу на гитхаб (я на самом не понимаю почему нужен лишь один файл) -  https://github.com/SatouAS/DB_EXAM  . Код проверен, есть в качестве проверки решение через скрипт psql (sql_dir/script_sql/script.sql нужное раскомментить). Смысла это делать в ipynb я не вижу, лучше полной системой. Там есть и скрин с результатами шага 3",
   "id": "84117349a381e7c4"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import date\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "# Тут подключение\n",
    "PG_URL      = \"jdbc:postgresql://postgres:5432/exam\"\n",
    "PG_PROPS    = {\"user\": \"satou\", \"password\": \"satou\", \"driver\": \"org.postgresql.Driver\"}\n",
    "\n",
    "MONGO_USER = \"satou\"\n",
    "MONGO_PASS = \"satou\"\n",
    "MONGO_HOST = \"mongo\"\n",
    "MONGO_PORT = 27017\n",
    "MONGO_DB   = \"mongo\"\n",
    "MONGO_COLL = \"reviews\"\n",
    "MONGO_URI  = f\"mongodb://{MONGO_USER}:{MONGO_PASS}@{MONGO_HOST}:{MONGO_PORT}/?authSource=admin\"\n",
    "\n",
    "# Здесь я поставил что отчетный день следующий после периода, если нужно реальный - datetime.utcnow().date()\n",
    "processing_date = date(2025, 9, 1)\n",
    "date_from = date(2025, 8, 1)\n",
    "date_to   = date(2025, 8, 31)\n",
    "\n",
    "# Блок подключения spark\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"product_analytics_monthly\")\n",
    "    .config(\n",
    "        \"spark.jars.packages\",\n",
    "        \"org.postgresql:postgresql:42.6.0,\"\n",
    "        \"org.mongodb.spark:mongo-spark-connector_2.12:10.2.0\"\n",
    "    )\n",
    "    .config(\"spark.mongodb.read.connection.uri\", MONGO_URI)\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# Запрос отчета за последние 30 дней (за 8 месяц) по разным колонкам\n",
    "orders_df = (\n",
    "    spark.read.format(\"jdbc\")\n",
    "    .option(\"url\", PG_URL)\n",
    "    .option(\"dbtable\", \"orders\")\n",
    "    .options(**PG_PROPS)\n",
    "    .load()\n",
    "    .filter(F.col(\"order_date\").between(F.lit(date_from), F.lit(date_to)))\n",
    "    .select(\"order_id\", \"order_date\")\n",
    ")\n",
    "\n",
    "order_items_df = (\n",
    "    spark.read.format(\"jdbc\")\n",
    "    .option(\"url\", PG_URL)\n",
    "    .option(\"dbtable\", \"order_items\")\n",
    "    .options(**PG_PROPS)\n",
    "    .load()\n",
    "    .select(\"order_id\", \"product_id\", \"quantity\", \"price\")\n",
    ")\n",
    "\n",
    "sales_metrics = (\n",
    "    order_items_df.join(orders_df, \"order_id\")\n",
    "    .groupBy(\"product_id\")\n",
    "    .agg(\n",
    "        F.countDistinct(\"order_id\").alias(\"order_count\"),\n",
    "        F.sum(\"quantity\").cast(\"long\").alias(\"total_quantity\"),\n",
    "        F.sum(F.col(\"quantity\") * F.col(\"price\")).cast(\"double\").alias(\"total_revenue\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Блок mongo\n",
    "reviews_raw = (\n",
    "    spark.read.format(\"mongodb\")\n",
    "    .option(\"uri\", MONGO_URI)\n",
    "    .option(\"database\", MONGO_DB)\n",
    "    .option(\"collection\", MONGO_COLL)\n",
    "    .load()\n",
    "    .select(\"product_id\", \"rating\", \"created_at\")\n",
    "    .withColumn(\"created_at\", F.to_timestamp(\"created_at\"))\n",
    "    .filter(F.col(\"created_at\").between(F.lit(date_from), F.lit(date_to)))\n",
    ")\n",
    "\n",
    "reviews_metrics = (\n",
    "    reviews_raw\n",
    "    .groupBy(\"product_id\")\n",
    "    .agg(\n",
    "        F.avg(\"rating\").alias(\"avg_rating\"),\n",
    "        F.count(\"*\").alias(\"total_reviews\"),\n",
    "        F.sum(F.when(F.col(\"rating\") >= 4, 1).otherwise(0)).alias(\"positive_reviews\"),\n",
    "        F.sum(F.when(F.col(\"rating\") <= 2, 1).otherwise(0)).alias(\"negative_reviews\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Блок объединения\n",
    "result_df = (\n",
    "    sales_metrics.join(reviews_metrics, \"product_id\", how=\"full_outer\")\n",
    "    .fillna(0, subset=[\"order_count\", \"total_quantity\", \"total_revenue\",\n",
    "                       \"avg_rating\", \"positive_reviews\",\n",
    "                       \"negative_reviews\", \"total_reviews\"])\n",
    "    .withColumn(\"processing_date\", F.lit(processing_date))\n",
    "    .select(\n",
    "        \"product_id\", \"total_quantity\", \"total_revenue\", \"order_count\",\n",
    "        \"avg_rating\", \"positive_reviews\", \"negative_reviews\",\n",
    "        \"total_reviews\", \"processing_date\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Запись в psql\n",
    "(\n",
    "    result_df.write\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"url\", PG_URL)\n",
    "    .option(\"dbtable\", \"product_analytics_monthly\")\n",
    "    .options(**PG_PROPS)\n",
    "    .mode(\"append\")\n",
    "    .save()\n",
    ")\n",
    "\n",
    "spark.stop()"
   ],
   "id": "8f90dc95a4d4559f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e9690a39220e062b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
